# Инструкция по эксплуатации

## Быстрый старт

### 1. Подготовка окружения

```bash
# Создайте виртуальное окружение
python3 -m venv .venv

# Активируйте его
source .venv/bin/activate  # Linux/Mac
# или
.venv\Scripts\activate     # Windows

# Установите зависимости
pip install -r requirements.txt
```

### 2. Настройка API ключей

Создайте файл `.env` в корне проекта:

```bash
GROQ_API_KEY=your_groq_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
PORT=5000
```

**Где получить ключи:**
- Groq: https://console.groq.com/
- OpenRouter: https://openrouter.ai/

### 3. Запуск сервера

**Важно:** Используйте Flask приложение, а НЕ простой HTTP сервер!

```bash
# Правильно - Flask приложение:
python app.py

# Или используйте скрипт:
./start.sh
```

**НЕ используйте:**
```bash
# ❌ НЕПРАВИЛЬНО - простой HTTP сервер не поддерживает POST запросы:
python3 -m http.server 8000
```

Сервер автоматически найдёт свободный порт (начиная с 5000) и выведет адрес в консоль.

## Использование

### Веб-интерфейс

1. Откройте браузер и перейдите на `http://localhost:5000`
2. Нажмите кнопку **"⚙️ НАСТРОЙКИ"** в правом верхнем углу
3. Настройте параметры:
   - Провайдер детекции (Groq/OpenRouter/Fallback)
   - Модель визии
   - Провайдер LLM
   - Температуру (0-1)
   - Максимальное количество токенов
4. Нажмите **"СОХРАНИТЬ"**
5. Загрузите изображение лица
6. Нажмите **"АНАЛИЗИРОВАТЬ"**

### API использование

#### Анализ изображения

```bash
curl -X POST http://localhost:5000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "image": "data:image/jpeg;base64,...",
    "config": {
      "detection_provider": "groq",
      "vision_model": "llama-3.2-90b-vision-preview",
      "temperature": 0.7
    }
  }'
```

#### Получить конфигурацию

```bash
curl http://localhost:5000/api/config
```

#### Обновить конфигурацию

```bash
curl -X POST http://localhost:5000/api/config \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 0.8,
    "max_tokens": 1500
  }'
```

## Настройки модели

### Провайдеры детекции

- **Groq** - Рекомендуется (быстрый, бесплатный)
- **OpenRouter** - Резервный вариант
- **Fallback** - Локальная имитация (для тестирования)

### Модели

**Vision модели:**
- `llama-3.2-90b-vision-preview` - Рекомендуется для анализа изображений
- `llama-3.1-70b-versatile` - Альтернатива

**Text модели:**
- `llama-3.1-70b-versatile` - Для генерации отчётов

### Параметры

- **Temperature** (0-1): Креативность ответов. 0.7 - оптимально
- **Max Tokens** (100-2000): Максимальная длина ответа. 1000 - оптимально

## Проверка работы API

### Как узнать, используются ли реальные данные или тестовые?

После анализа в интерфейсе отображается информация о провайдере:

- ✅ **"ПРОВАЙДЕР: GROQ"** или **"ПРОВАЙДЕР: OPENROUTER"** - используются реальные данные из API
- ⚠️ **"ВНИМАНИЕ: ИСПОЛЬЗУЮТСЯ ТЕСТОВЫЕ ДАННЫЕ"** - используются случайные тестовые данные (API недоступны)

### Запуск тестов

```bash
python test_api.py
```

Тесты покажут, какие API работают, а какие нет.

## Troubleshooting

### Ошибка "API key not found"

Проверьте, что файл `.env` существует и содержит правильные ключи.

### Ошибка "Все API недоступны"

Если вы видите эту ошибку:
1. Проверьте API ключи в `.env` файле
2. Запустите тесты: `python test_api.py`
3. Проверьте логи сервера - там будет указано, почему API не работают
4. Убедитесь, что у вас есть интернет-соединение
5. Проверьте, что API ключи действительны и не истекли

**Важно:** Сервис не использует случайные/тестовые данные. Если API недоступны, возвращается ошибка.

### Ошибка "Connection timeout"

- Проверьте интернет-соединение
- Убедитесь, что API ключи действительны
- Попробуйте другой провайдер (fallback)

### Медленный анализ

- Используйте Groq (быстрее)
- Уменьшите `max_tokens`
- Проверьте размер изображения (рекомендуется < 2MB)

### Неточные результаты

- Увеличьте `temperature` до 0.8-0.9
- Используйте модель `llama-3.2-90b-vision-preview`
- Убедитесь, что изображение хорошего качества

## Производственное развёртывание

### Использование Gunicorn

```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

### Использование Docker

Создайте `Dockerfile`:

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "app.py"]
```

```bash
docker build -t skin-analyzer .
docker run -p 5000:5000 --env-file .env skin-analyzer
```

## Мониторинг

Логи выводятся в консоль. Для production используйте:

```bash
python app.py > app.log 2>&1
```

## Безопасность

- Никогда не коммитьте `.env` файл в git
- Используйте HTTPS в production
- Ограничьте размер загружаемых изображений
- Добавьте rate limiting для API

## Поддержка

При возникновении проблем проверьте:
1. Логи в консоли
2. Правильность API ключей
3. Доступность API провайдеров
4. Формат изображения (JPEG/PNG)

